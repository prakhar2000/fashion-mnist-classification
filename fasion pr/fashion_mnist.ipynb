{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "# from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import cv2\n",
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 25\n",
    "INIT_LR = 1e-2\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# minivggnet build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "\n",
    "\t\t# first CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading Fashion MNIST...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == \"channels_first\":\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "\ttestX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    " \n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "# one-hot encode the training and testing labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "# initialize the label names\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 204s 109ms/step - loss: 0.5394 - accuracy: 0.8195 - val_loss: 0.3210 - val_accuracy: 0.8811\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 212s 113ms/step - loss: 0.3407 - accuracy: 0.8787 - val_loss: 0.2770 - val_accuracy: 0.8996\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 213s 114ms/step - loss: 0.2942 - accuracy: 0.8935 - val_loss: 0.2560 - val_accuracy: 0.9048\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 205s 109ms/step - loss: 0.2678 - accuracy: 0.9052 - val_loss: 0.2336 - val_accuracy: 0.9135\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 205s 109ms/step - loss: 0.2514 - accuracy: 0.9090 - val_loss: 0.2263 - val_accuracy: 0.9185\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 209s 111ms/step - loss: 0.2401 - accuracy: 0.9130 - val_loss: 0.2178 - val_accuracy: 0.9206\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 206s 110ms/step - loss: 0.2313 - accuracy: 0.9162 - val_loss: 0.2177 - val_accuracy: 0.9221\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 207s 110ms/step - loss: 0.2214 - accuracy: 0.9204 - val_loss: 0.2124 - val_accuracy: 0.9217\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 213s 114ms/step - loss: 0.2158 - accuracy: 0.9215 - val_loss: 0.2021 - val_accuracy: 0.9271\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 211s 113ms/step - loss: 0.2092 - accuracy: 0.9242 - val_loss: 0.2007 - val_accuracy: 0.9266\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 235s 125ms/step - loss: 0.2058 - accuracy: 0.9245 - val_loss: 0.1992 - val_accuracy: 0.9286\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 183s 98ms/step - loss: 0.2009 - accuracy: 0.9275 - val_loss: 0.1972 - val_accuracy: 0.9275\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 194s 103ms/step - loss: 0.1969 - accuracy: 0.9283 - val_loss: 0.1926 - val_accuracy: 0.9286\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 184s 98ms/step - loss: 0.1928 - accuracy: 0.9301 - val_loss: 0.1986 - val_accuracy: 0.9298\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 184s 98ms/step - loss: 0.1885 - accuracy: 0.9314 - val_loss: 0.1920 - val_accuracy: 0.9292\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 183s 98ms/step - loss: 0.1883 - accuracy: 0.9318 - val_loss: 0.1930 - val_accuracy: 0.9300\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 193s 103ms/step - loss: 0.1850 - accuracy: 0.9328 - val_loss: 0.1917 - val_accuracy: 0.9292\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 186s 99ms/step - loss: 0.1795 - accuracy: 0.9345 - val_loss: 0.1906 - val_accuracy: 0.9305\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 186s 99ms/step - loss: 0.1784 - accuracy: 0.9357 - val_loss: 0.1864 - val_accuracy: 0.9308\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.1787 - accuracy: 0.9346 - val_loss: 0.1854 - val_accuracy: 0.9319\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 0.1763 - accuracy: 0.9359 - val_loss: 0.1849 - val_accuracy: 0.9329\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 175s 94ms/step - loss: 0.1733 - accuracy: 0.9368 - val_loss: 0.1881 - val_accuracy: 0.9323\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 176s 94ms/step - loss: 0.1726 - accuracy: 0.9372 - val_loss: 0.1870 - val_accuracy: 0.9337\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 185s 99ms/step - loss: 0.1703 - accuracy: 0.9378 - val_loss: 0.1843 - val_accuracy: 0.9339\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 181s 97ms/step - loss: 0.1704 - accuracy: 0.9385 - val_loss: 0.1839 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training model...\")\n",
    "H = model.fit(x=trainX, y=trainY,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tbatch_size=BS, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.90      0.88      0.89      1000\n",
      "     trouser       0.99      0.99      0.99      1000\n",
      "    pullover       0.89      0.92      0.90      1000\n",
      "       dress       0.93      0.94      0.94      1000\n",
      "        coat       0.88      0.91      0.90      1000\n",
      "      sandal       0.99      0.99      0.99      1000\n",
      "       shirt       0.81      0.78      0.79      1000\n",
      "     sneaker       0.96      0.98      0.97      1000\n",
      "         bag       0.99      0.99      0.99      1000\n",
      "  ankle boot       0.98      0.96      0.97      1000\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds = model.predict(testX)\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),target_names=labelNames))\n",
    "\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
    "\t\n",
    "\tprobs = model.predict(testX[np.newaxis, i])\n",
    "\tprediction = probs.argmax(axis=1)\n",
    "\tlabel = labelNames[prediction[0]]\n",
    " \n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\timage = (testX[i][0] * 255).astype(\"uint8\")\n",
    "\n",
    "\telse:\n",
    "\t\timage = (testX[i] * 255).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
